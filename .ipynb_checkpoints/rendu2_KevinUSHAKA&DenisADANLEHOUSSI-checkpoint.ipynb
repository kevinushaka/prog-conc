{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Gestion de la Concurrence\n",
    "\n",
    "**Kévin** **Ushaka**\n",
    "\n",
    "**Denis** **ADANLEHOUSSI**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Référence(s):\n",
    "    https://docs.python.org/fr/3/library/_thread.html\n",
    "    http://effbot.org/zone/thread-synchronization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un verrou primitif est soit « verrouillé » soit « déverrouillé ». Il est créé dans un état déverrouillé. Il a deux méthodes, acquire() et release(). Lorsque l'état est déverrouillé, acquire() verrouille et se termine immédiatement. Lorsque l'état est verrouillé, acquire() bloque jusqu'à ce qu'un appel à release() provenant d'un autre fil d'exécution le déverrouille.\n",
    "\n",
    "Lorsque plus d'un thread est bloqué dans acquire () en attendant que l'état passe à déverrouillé, un seul thread se poursuit lorsqu'un appel release () réinitialise l'état à déverrouillé; lequel des threads en attente continue n'est pas défini et peut varier selon les implémentations.\n",
    "\n",
    "Pour un fonctionnement correct, il est important de libérer le verrou même si quelque chose ne va pas lors de l’accès à la ressource. On peut utiliser try-finally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lock.acquire()\n",
    "try:\n",
    "    ... access shared resource\n",
    "finally:\n",
    "    lock.release() # release lock, no matter wha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode acquire() prend un indicateur d'attente facultatif, qui peut être utilisé pour éviter le blocage si le verrou est détenu par quelqu'un d'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not lock.acquire(False):\n",
    "    ... failed to lock the resource\n",
    "else:\n",
    "    try:\n",
    "        ... access shared resource\n",
    "    finally:\n",
    "        lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exemple suivant, deux methodes utilisent une même varible globale g, on gère pas les sections critqiues.\n",
    "\n",
    "Dans add_one_one() on reinitialise g à 0 puis on l'incrément de 1. Par la suite on cré une boucle de 30 avec affichage de texte juste pour faire durer l'execution de la methode . On incremente encore une fois g avant de l'afficher La resultat attendu appres cette afficheage est donc 2.\n",
    "\n",
    "Dans add_two() on incremente juste g de 2.\n",
    "\n",
    "Nous appelons deux threads sur ces deux methodes (add_one_one() en premier et add_two() apres).\n",
    "Notons que l'on attends que les deux threads se termine ( fonction join()), pour afficher le résultat seulement lexecution totale des deux Threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "boucle d'attente\n",
      "Affichage de g dans add one one : 4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#lock_tut.py\n",
    "from threading import Lock, Thread\n",
    "lock = Lock()\n",
    "g = 0\n",
    "\n",
    "def add_one_one():\n",
    "\n",
    "   global g\n",
    "   g=0\n",
    "   g += 1\n",
    "   for i in range(30):\n",
    "     print('boucle d\\'attente')\n",
    "   g += 1\n",
    "   print('Affichage de g dans add one one :',g)\n",
    "\n",
    "def add_two():\n",
    "   global g\n",
    "   g += 2\n",
    "\n",
    "threads = []\n",
    "for func in [add_one_one, add_two]:\n",
    "   threads.append(Thread(target=func))\n",
    "\n",
    "threads[0].start() \n",
    "threads[1].start()\n",
    "\n",
    "for thread in threads:\n",
    "   \"\"\"\n",
    "   Waits for threads to complete before moving on with the main\n",
    "   script.\n",
    "   \"\"\"\n",
    "   thread.join()\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exemple suivant, nous gèrons les sections critqiues avec le verrou threading.Lock. On obtient toujours 2 pour l'affichage dans add_one_one et 4 à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock_tut.py\n",
    "from threading import Lock, Thread\n",
    "lock = Lock()\n",
    "g = 0\n",
    "\n",
    "def add_one():\n",
    "   global g\n",
    "   lock.acquire()\n",
    "   g=0\n",
    "   g += 1\n",
    "   for i in range(30):\n",
    "     print('boucle d\\'attente')\n",
    "   g += 1\n",
    "   print('Affichage de g dans add one :',g)\n",
    "   lock.release()\n",
    "\n",
    "def add_two():\n",
    "   global g\n",
    "   lock.acquire()\n",
    "   g += 2\n",
    "   lock.release()\n",
    "\n",
    "threads = []\n",
    "for func in [add_one, add_two]:\n",
    "   threads.append(Thread(target=func))\n",
    "   threads[-1].start()\n",
    "\n",
    "for thread in threads:\n",
    "   \"\"\"\n",
    "   Waits for threads to complete before moving on with the main\n",
    "   script.\n",
    "   \"\"\"\n",
    "   thread.join()\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet de verrouillage standard ne se soucie pas du thread qui détient actuellement le verrou; si le verrou est maintenu, tout thread qui tente d'acquérir le verrou se bloque, même si le même thread détient déjà le verrou. Dans l'exemple suivant, les fonctions get_first_part() et get_second_part() resteront bloquées, car la fonction externe increment() détient déjà le verrou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First try : True\n",
      "Second try: False\n",
      "print this if not blocked...\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "print('First try :',lock.acquire())\n",
    "print('Second try:',lock.acquire(0))\n",
    "print(\"print this if not blocked...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe RLock est une version du verrouillage qui ne se bloque que si le verrou est détenu par un autre thread. Alors que les verrous simples se bloquent si le même thread tente d'acquérir le même verrou deux fois, un verrou rentrant ne se bloque que si un autre thread détient actuellement le verrou. Si le thread actuel tente d'acquérir un verrou qu'il détient déjà, l'exécution se poursuit comme d'habitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First try : True\n",
      "Second try: True\n",
      "print this if not blocked...\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "lock = threading.RLock()\n",
    "\n",
    "print('First try :', lock.acquire())\n",
    "print('Second try:', lock.acquire(blocking = True, timeout = -1))\n",
    "print(\"print this if not blocked...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En reprenant le même exemple mais avec un ReLock, , on réussi à réobtenir le verrou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semaphore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un sémaphore gère un compteur interne qui est décrémenté à chaque appel acquise () et incrémenté à chaque appel release (). Le compteur ne peut jamais descendre en dessous de zéro; quand acquiert () trouve qu'il est égal à zéro, il bloque, en attendant qu'un autre thread appelle release ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import threading\n",
    "             \n",
    "class Counter(object):\n",
    "    def __init__(self, start = 0):\n",
    "        self.semaphore = threading.BoundedSemaphore(value=1)\n",
    "        self.value = start\n",
    "    def increment(self):\n",
    "        print('Waiting for a lock')\n",
    "        self.semaphore.acquire()\n",
    "        try:\n",
    "            print('Acquired a lock')\n",
    "            self.value = self.value + 1\n",
    "        finally:\n",
    "            print('Released a lock')\n",
    "            self.semaphore.release()\n",
    "\n",
    "def worker(c):\n",
    "    c.increment()\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "my_list=[]\n",
    "counter = Counter()\n",
    "for i in range(2):\n",
    "    t = threading.Thread(target=worker, args=(counter,))\n",
    "    my_list.append(t)\n",
    "    t.start()\n",
    "\n",
    "print('Waiting for worker threads')\n",
    "main_thread = threading.currentThread()\n",
    "for t in my_list:\n",
    "    t.join()\n",
    "print('Counter:'+ str(counter.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barrier\n",
    "\n",
    "Une barrière est une simple primitive de synchronisation qui peut être utilisée par différents threads pour s'attendre les uns les autres. Chaque thread tente de passer une barrière en appelant la wait()méthode, qui se bloquera jusqu'à ce que tous les threads aient effectué cet appel. Dès que cela se produit, les threads sont libérés simultanément. L'extrait de code suivant illustre l'utilisation de Barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barrier_tut.py\n",
    "from random import randrange\n",
    "from threading import Barrier, Thread\n",
    "from time import ctime, sleep\n",
    "\n",
    "num = 4\n",
    "# 4 threads will need to pass this barrier to get released.\n",
    "b = Barrier(num)\n",
    "names = [\"Harsh\", \"Lokesh\", \"George\", \"Iqbal\"]\n",
    "\n",
    "def player():\n",
    "    name = names.pop()\n",
    "    sleep(randrange(2, 5))\n",
    "    print(\"%s reached the barrier at: %s\" % (name, ctime()))\n",
    "    b.wait()\n",
    "    \n",
    "threads = []\n",
    "print(\"Race starts now…\")\n",
    "\n",
    "for i in range(num):\n",
    "    threads.append(Thread(target=player))\n",
    "    threads[-1].start()\n",
    "\"\"\"\n",
    "Following loop enables waiting for the threads to complete before moving on with the main script.\n",
    "\"\"\"\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "print()\n",
    "print(\"Race over!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objet Event\n",
    "\n",
    "Nous utilisons plusieurs threads pour faire tourner des opérations séparées afin de les exécuter simultanément, cependant, il y a des moments où il est important de pouvoir synchroniser les opérations de deux ou plusieurs threads. L'utilisation d' objets Event est le moyen simple de communiquer entre les threads.\n",
    "\n",
    "Un événement gère un indicateur interne que les appelants peuvent définir () ou effacer () . D'autres threads peuvent attendre () que l'indicateur soit défini () . Notez que la méthode wait () se bloque jusqu'à ce que l'indicateur soit vrai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(%(threadName)-9s) %(message)s',)\n",
    "                    \n",
    "def wait_for_event(e):\n",
    "    logging.debug('wait_for_event starting')\n",
    "    event_is_set = e.wait()\n",
    "    logging.debug('event set: %s', event_is_set)\n",
    "\n",
    "def wait_for_event_timeout(e, t):\n",
    "    while not e.isSet():\n",
    "        logging.debug('wait_for_event_timeout starting')\n",
    "        event_is_set = e.wait(t)\n",
    "        logging.debug('event set: %s', event_is_set)\n",
    "        if event_is_set:\n",
    "            logging.debug('processing event')\n",
    "        else:\n",
    "            logging.debug('doing other things')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    e = threading.Event()\n",
    "    t1 = threading.Thread(name='blocking', \n",
    "                      target=wait_for_event,\n",
    "                      args=(e,))\n",
    "    t1.start()\n",
    "\n",
    "    t2 = threading.Thread(name='non-blocking', \n",
    "                      target=wait_for_event_timeout, \n",
    "                      args=(e, 2))\n",
    "    t2.start()\n",
    "\n",
    "    logging.debug('Waiting before calling Event.set()')\n",
    "    time.sleep(3)\n",
    "    e.set()\n",
    "    logging.debug('Event is set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le processus ont leur propre espace virtuel, ils ne pas partagent leur mémoire. C'est pourquoi le module multiprocessing gère deux types de canaux de communication entre les processus : Queue , Tubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def f(q):\n",
    "    q.put([42, None, 'hello'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    p = Process(target=f, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())    # prints \"[42, None, 'hello']\"\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser un tube on instancie un objet Pipe. Les deux objets de connexion renvoyés par Pipe() représentent les deux bouts d'un tube. Chaque objet de connexion possède des méthodes send() et recv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de créer des objets partagés utilisant une mémoire partagée pouvant être héritée par les processus enfants avec multiprocessing.Value(typecode_or_type, *args, lock=True).\n",
    "\n",
    "Les opérations telles que += qui impliquent une lecture et une écriture ne sont pas atomique. Ainsi si on souhaite par exemple réaliser une incrémentation atomique sur une valeur partagée, on ne peut pas simplement faire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import multiprocessing \n",
    "\n",
    "# function to deposit to account \n",
    "def increment(variable):     \n",
    "    variable.value = variable.value + 1\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    counter = multiprocessing.Value('i', 0)\n",
    "\n",
    "    p1 = multiprocessing.Process(target=increment, args=(counter,)) \n",
    "    p2 = multiprocessing.Process(target=increment, args=(counter,)) \n",
    "  \n",
    "    p1.start() \n",
    "    p2.start() \n",
    "\n",
    "    p1.join();\n",
    "    p2.join();\n",
    "\n",
    "    print(\"Final balance = \"+str(counter.value)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paquet multiprocessing reproduit en grande partie l'API du module threading. O nretrouve les primitives de synchronisation :\n",
    "multiprocessing.Lock\n",
    "multiprocessing.RLock\n",
    "multiprocessing.BoundedSemaphore([value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un verrou non récursif : un analogue proche de threading.Lock. Une fois que le processus ou le fil d'exécution a acquis un verrou, les tentatives suivantes d'acquisition depuis n'importe quel processus ou fil d'exécution bloqueront jusqu'à ce qu'il soit libéré ; n'importe quel processus ou fil peut le libérer. Les concepts et comportements de threading.Lock qui s'appliquent aux fils d'exécution sont répliqués ici dans multiprocessing.Lock et s'appliquent aux processus et aux fils d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing \n",
    "  \n",
    "# function to withdraw from account \n",
    "def withdraw(balance, lock):     \n",
    "    for _ in range(10000): \n",
    "        lock.acquire() \n",
    "        balance.value = balance.value - 1\n",
    "        lock.release() \n",
    "  \n",
    "# function to deposit to account \n",
    "def deposit(balance, lock):     \n",
    "    for _ in range(10000): \n",
    "        lock.acquire() \n",
    "        balance.value = balance.value + 1\n",
    "        lock.release() \n",
    "  \n",
    "def perform_transactions(): \n",
    "  \n",
    "    # initial balance (in shared memory) \n",
    "    balance = multiprocessing.Value('i', 100) \n",
    "  \n",
    "    # creating a lock object \n",
    "    lock = multiprocessing.Lock() \n",
    "  \n",
    "    # creating new processes \n",
    "    p1 = multiprocessing.Process(target=withdraw, args=(balance,lock)) \n",
    "    p2 = multiprocessing.Process(target=deposit, args=(balance,lock)) \n",
    "  \n",
    "    # starting processes \n",
    "    p1.start() \n",
    "    p2.start() \n",
    "  \n",
    "    # wait until processes are finished \n",
    "    p1.join() \n",
    "    p2.join() \n",
    "  \n",
    "    # print final balance \n",
    "    print(\"Final balance = \"+str(balance.value)) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    for _ in range(10): \n",
    "  \n",
    "        # perform same transaction process 10 times \n",
    "        perform_transactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RLock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un objet verrou récursif : un analogue proche de threading.RLock. Un verrou récursif doit être libéré par le processus ou le fil d'exécution qui l'a acquis. Quand un processus ou un fil acquiert un verrou récursif, le même processus/fil peut l'acquérir à nouveau sans bloquer ; le processus/fil doit le libérer autant de fois qu'il l'acquiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semaphore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une seule différence existe avec son proche analogue : le premier argument de sa méthode acquire est appelé block, pour la cohérence avec Lock.acquire()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
